# RumiGAN
Generative adversarial networks (GANs) were originally envisioned as unsupervised generative models that learn to follow a target distribution. Variants such as conditional GANs, and auxiliary-classifier GANs (ACGANs) project GANs onto supervised and semi-supervised learning frameworks by providing labeled data and using multi-class discriminators. In the GAN framework, we not only provide the GAN positive data that it must learn to model, but also present it with so-called negative samples that it must learn to avoid - we call this "The Rumi Framework." This formulation allows the discriminator to represent the underlying target distribution better by learning to penalize generated samples that are undesirable - we show that this capability accelerates the learning process of the generator. I present a reformulation of the standard GAN (SGAN) and least-squares GAN (LSGAN) within the Rumi setting.

The sample folder contains the images generated by providing even digits as a negative class and od digits as a negative one. GAN learns to penalize the even digits and thus generates only odd digits.
